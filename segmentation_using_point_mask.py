# -*- coding: utf-8 -*-
"""Segmentation_using_point_mask.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1iTW3TJatmf1ce8J_e_ti265M4VOwXOXJ

# Using "Satellite Images of Water Bodies" dataset from kaggle
"""

!kaggle datasets download -d franciscoescobar/satellite-images-of-water-bodies

"""## Unzip the dataset"""

!unzip "/content/satellite-images-of-water-bodies.zip"

"""# Notebook Will have 2 parts
## Mask Segmentation
## Point Segmentaion wich is also refred to as incomplete Tagging

# Complete Mask Segmentation
"""

import os
import cv2 as cv
from keras.metrics import MeanIoU
from tqdm import tqdm
import numpy as np
from keras.preprocessing.image import load_img, img_to_array
import matplotlib.pyplot as plt
import keras
import tensorflow as tf
from keras.layers import Conv2D, MaxPool2D, Dropout, BatchNormalization, Input, Conv2DTranspose, concatenate, GlobalAveragePooling2D, Dense
from keras import Sequential
from keras.callbacks import EarlyStopping, ModelCheckpoint

def show_image(image, cmap=None, title=None):
  plt.imshow(image, cmap=cmap)
  if title is not None: plt.title(title)
  plt.axis('off')

images = list()
mask = list()

image_path = '/content/Water Bodies Dataset/Images/'
mask_path = '/content/Water Bodies Dataset/Masks/'

image_names = sorted(next(os.walk(image_path))[-1])
mask_names = sorted(next(os.walk(mask_path))[-1])

if image_names == mask_names:
  print('Image and Mask are corretly Placed!!')

SIZE = 128
images = np.zeros(shape=(len(image_names),SIZE, SIZE, 3))
masks = np.zeros(shape=(len(image_names),SIZE, SIZE, 1))

for id in tqdm(range(len(image_names)), desc="Images"):
  path = image_path + image_names[id]
  img = img_to_array(load_img(path)).astype('float')/255.
  img = cv.resize(img, (SIZE,SIZE), cv.INTER_AREA)
  images[id] = img

for id in tqdm(range(len(mask_names)), desc="Mask"):
  path = mask_path + mask_names[id]
  mask = img_to_array(load_img(path)).astype('float')/255.
  mask = cv.resize(mask, (SIZE,SIZE), cv.INTER_AREA)
  masks[id] = mask[:,:,:1]

plt.figure(figsize=(15,15))
for i in range(1,21):
  plt.subplot(5,4,i)

  if i%2!=0:
    id = np.random.randint(len(images))
    show_image(images[id], title="Orginal Image")
  elif i%2==0:
    show_image(masks[id].reshape(128,128), title="Mask Image", cmap='gray')

plt.tight_layout()
plt.show()

X, y = images[:int(len(images)*0.9)], masks[:int(len(images)*0.9)]
test_X, test_y = images[int(len(images)*0.9):], masks[int(len(images)*0.9):]

# Contraction
class EncoderBlock(keras.layers.Layer):

  def __init__(self, filters, rate=None, pooling=True):
    super(EncoderBlock,self).__init__()
    self.filters = filters
    self.rate = rate
    self.pooling = pooling
    self.conv1 = Conv2D(self.filters,kernel_size=3,strides=1,padding='same',activation='relu',kernel_initializer='he_normal')
    self.conv2 = Conv2D(self.filters,kernel_size=3,strides=1,padding='same',activation='relu',kernel_initializer='he_normal')
    if self.pooling: self.pool = MaxPool2D(pool_size=(2,2))
    if self.rate is not None: self.drop = Dropout(rate)

  def call(self, inputs):
    x = self.conv1(inputs)
    if self.rate is not None: x = self.drop(x)
    x = self.conv2(x)
    if self.pooling:
      y = self.pool(x)
      return y, x
    else:
      return x

  def get_config(self):
    base_config = super().get_config()
    return {
        **base_config,
        "filters":self.filters,
        "rate":self.rate,
        "pooling":self.pooling
    }

# Expansion
class DecoderBlock(keras.layers.Layer):

  def __init__(self, filters, rate=None, axis=-1):
    super(DecoderBlock,self).__init__()
    self.filters = filters
    self.rate = rate
    self.axis = axis
    self.convT = Conv2DTranspose(self.filters,kernel_size=3,strides=2,padding='same')
    self.conv1 = Conv2D(self.filters, kernel_size=3, activation='relu', kernel_initializer='he_normal', padding='same')
    if rate is not None: self.drop = Dropout(self.rate)
    self.conv2 = Conv2D(self.filters, kernel_size=3, activation='relu', kernel_initializer='he_normal', padding='same')

  def call(self, inputs):
    X, short_X = inputs
    ct = self.convT(X)
    c_ = concatenate([ct, short_X], axis=self.axis)
    x = self.conv1(c_)
    if self.rate is not None: x = self.drop(x)
    y = self.conv2(x)
    return y

  def get_config(self):
    base_config = super().get_config()
    return {
        **base_config,
        "filters":self.filters,
        "rate":self.rate,
        "axis":self.axis,
    }

# Callback
class ShowProgress(keras.callbacks.Callback):
  def __init__(self, save=False):
    self.save = save
  def on_epoch_end(self, epoch, logs=None):
    id = np.random.randint(len(images))
    real_img = images[id][np.newaxis,...]
    pred_mask = self.model.predict(real_img).reshape(128,128)
    proc_mask1 = post_process(pred_mask)
    proc_mask2 = post_process(pred_mask, threshold=0.5)
    proc_mask3 = post_process(pred_mask, threshold=0.9)
    mask = masks[id].reshape(128,128)

    plt.figure(figsize=(10,5))

    plt.subplot(1,6,1)
    show_image(real_img[0], title="Orginal Image")

    plt.subplot(1,6,2)
    show_image(pred_mask, title="Predicted Mask", cmap='gray')

    plt.subplot(1,6,3)
    show_image(mask, title="Orginal Mask", cmap='gray')

    plt.subplot(1,6,4)
    show_image(proc_mask1, title="Processed@0.4", cmap='gray')

    plt.subplot(1,6,5)
    show_image(proc_mask2, title="Processed@0.5", cmap='gray')

    plt.subplot(1,6,6)
    show_image(proc_mask3, title="Processed@0.9", cmap='gray')

    plt.tight_layout()
    if self.save: plt.savefig("Progress-{}.png".format(epoch+1))
    plt.show()

# Post Process
def post_process(image,threshold=0.4):
  return image>threshold

inputs= Input(shape=(SIZE,SIZE,3))

# Contraction
p1, c1 = EncoderBlock(16,0.1)(inputs)
p2, c2 = EncoderBlock(32,0.1)(p1)
p3, c3 = EncoderBlock(64,0.2)(p2)
p4, c4 = EncoderBlock(128,0.2)(p3)

# Encoding Layer
c5 = EncoderBlock(256,rate=0.3,pooling=False)(p4)

# Expansion
d1 = DecoderBlock(128,0.2)([c5,c4]) # [current_input, skip_connection]
d2 = DecoderBlock(64,0.2)([d1,c3])
d3 = DecoderBlock(32,0.1)([d2,c2])
d4 = DecoderBlock(16,0.1, axis=3)([d3,c1])

# Outputs
outputs = Conv2D(1,1,activation='sigmoid')(d4)

unet = keras.models.Model(
    inputs=[inputs],
    outputs=[outputs],
)

unet.compile(
    loss='binary_crossentropy',
    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
    metrics=['accuracy']
)

callbacks = [
    EarlyStopping(patience=3, restore_best_weights=True),
    ModelCheckpoint('UNet-01.h5',save_best_only=True),
    ShowProgress(save=True)
]

unet.summary()

# Commented out IPython magic to ensure Python compatibility.
# %%time
# with tf.device("/GPU:0"):
#   results = unet.fit(
#       X, y,
#       epochs=100,
#       callbacks=callbacks,
#       validation_split=0.1,
#       batch_size=16
#   )

meanIoU = MeanIoU(num_classes=2)
for image, mask in zip(test_X, test_y):
    pred_mask = unet.predict(image[np.newaxis,...])
    meanIoU.update_state(mask, pred_mask)
print(meanIoU.result().numpy())

"""# Point Based Segmentation"""

import os
import cv2
import matplotlib.pyplot as plt

image_dir = '/content/Water Bodies Dataset/Images'
mask_dir = '/content/Water Bodies Dataset/Masks'

image_files = sorted(os.listdir(image_dir))
mask_files = sorted(os.listdir(mask_dir))

def load_image_and_mask(image_path, mask_path):
    image = cv2.imread(image_path)
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
    return image, mask

fig, axs = plt.subplots(3, 2, figsize=(10, 15))

for i in range(3):
    image_path = os.path.join(image_dir, image_files[i])
    mask_path = os.path.join(mask_dir, mask_files[i])
    image, mask = load_image_and_mask(image_path, mask_path)

    axs[i, 0].imshow(image)
    axs[i, 0].set_title('Image')
    axs[i, 0].axis('off')

    axs[i, 1].imshow(mask, cmap='gray')
    axs[i, 1].set_title('Mask')
    axs[i, 1].axis('off')

plt.tight_layout()
plt.show()

"""## A New Directory to Save Point masks"""

!mkdir -p "/content/Water Bodies Dataset/Point_Masks"

"""## generating Point Labels from the masks for incomplete tagging"""

import os
import cv2
import numpy as np
import matplotlib.pyplot as plt
import torch

# Define directories
image_dir = '/content/Water Bodies Dataset/Images'
mask_dir = '/content/Water Bodies Dataset/Masks'
path_point_masks = "/content/Water Bodies Dataset/Point_Masks"

os.makedirs(path_point_masks, exist_ok=True)

image_files = sorted(os.listdir(image_dir))
mask_files = sorted(os.listdir(mask_dir))

def load_image_and_mask(image_path, mask_path):
    image = cv2.imread(image_path)
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
    return image, mask

for i in range(3):
    image_path = os.path.join(image_dir, image_files[i])
    mask_path = os.path.join(mask_dir, mask_files[i])
    image, mask = load_image_and_mask(image_path, mask_path)

def generate_point_labels(full_masks, num_points=10):
    """
    Simulate point labels from full segmentation masks.
    full_masks: List of masks as numpy arrays.
    num_points: Number of point labels to sample per image.
    """
    point_labels = []
    for mask in full_masks:
        points_mask = np.zeros_like(mask)
        indices = np.argwhere(mask > 0)
        selected_indices = indices[np.random.choice(indices.shape[0], num_points, replace=False)]
        for ind in selected_indices:
            points_mask[ind[0], ind[1]] = mask[ind[0], ind[1]]
        point_labels.append(points_mask)
    return point_labels

masks = [cv2.imread(os.path.join(mask_dir, mask_file), cv2.IMREAD_GRAYSCALE) for mask_file in mask_files]

point_labels = generate_point_labels(masks, num_points=200)
print(len(point_labels))

# Save point masks with the same names as the mask files
for i, point_mask in enumerate(point_labels):
    mask_file_name = mask_files[i]
    save_path = os.path.join(path_point_masks, mask_file_name)
    cv2.imwrite(save_path, point_mask)
    print(f"Saved: {save_path}")

# Optional: Display some masks and point labels for verification
for i in range(10):
    plt.figure(figsize=(10, 5))
    plt.subplot(1, 2, 1)
    plt.imshow(masks[i], cmap='gray')
    plt.title('Original Mask')
    plt.subplot(1, 2, 2)
    plt.imshow(point_labels[i], cmap='gray')
    plt.title('Point Labels')
    plt.show()

for i in range(10):
    plt.figure(figsize=(10, 5))
    plt.subplot(1, 2, 1)
    plt.imshow(masks[i + 100], cmap='gray')
    plt.title('Original Mask')
    plt.subplot(1, 2, 2)
    plt.imshow(point_labels[i + 100], cmap='gray')
    plt.title('Point Labels')
    plt.show()

"""# PartialCrossEntropyLoss Implementation"""

import torch.nn as nn
import torch.nn.functional as F

class PartialCrossEntropyLoss(nn.Module):
    def __init__(self):
        super(PartialCrossEntropyLoss, self).__init__()

    def forward(self, predictions, targets, mask):
        targets = targets * mask
        predictions = predictions.permute(0, 2, 3, 1)
        predictions = predictions[mask == 1]
        targets = targets[mask == 1].long()

        if targets.numel() == 0:
            return torch.tensor(0.0, requires_grad=True, device=predictions.device)

        loss = F.cross_entropy(predictions, targets)
        return loss

images = list()
mask = list()

image_path = '/content/Water Bodies Dataset/Images/'
point_mask_path = '/content/Water Bodies Dataset/Point_Masks/'

image_names = sorted(next(os.walk(image_path))[-1])
point_mask_names = sorted(next(os.walk(point_mask_path))[-1])

if image_names == point_mask_names:
  print('Images and point masks are corretly Placed!!')
else:
  print("They are not")

SIZE = 128
images = np.zeros(shape=(len(image_names),SIZE, SIZE, 3))
masks = np.zeros(shape=(len(image_names),SIZE, SIZE, 1))

for id in tqdm(range(len(image_names)), desc="Images"):
  path = image_path + image_names[id]
  img = img_to_array(load_img(path)).astype('float')/255.
  img = cv.resize(img, (SIZE,SIZE), cv.INTER_AREA)
  images[id] = img

for id in tqdm(range(len(point_mask_names)), desc="Mask"):
  path = point_mask_path + point_mask_names[id]
  mask = img_to_array(load_img(path)).astype('float')/255.
  mask = cv.resize(mask, (SIZE,SIZE), cv.INTER_AREA)
  masks[id] = mask[:,:,:1]

plt.figure(figsize=(15,15))
for i in range(1,21):
  plt.subplot(5,4,i)

  if i%2!=0:
    id = np.random.randint(len(images))
    show_image(images[id], title="Orginal Image")
  elif i%2==0:
    show_image(masks[id].reshape(128,128), title="Point Mask Image", cmap='gray')

plt.tight_layout()
plt.show()

X, y = images[:int(len(images)*0.9)], masks[:int(len(images)*0.9)]
test_X, test_y = images[int(len(images)*0.9):], masks[int(len(images)*0.9):]

# Post Process
def post_process(image,threshold=0.4):
  return image>threshold


def enhance_contrast(image):
    img_uint8 = np.uint8(image * 255)
    enhanced_img = cv2.equalizeHist(img_uint8)
    enhanced_img = np.float32(enhanced_img) / 255.0
    return enhanced_img

# Contraction
class EncoderBlock(keras.layers.Layer):

  def __init__(self, filters, rate=None, pooling=True):
    super(EncoderBlock,self).__init__()
    self.filters = filters
    self.rate = rate
    self.pooling = pooling
    self.conv1 = Conv2D(self.filters,kernel_size=3,strides=1,padding='same',activation='relu',kernel_initializer='he_normal')
    self.conv2 = Conv2D(self.filters,kernel_size=3,strides=1,padding='same',activation='relu',kernel_initializer='he_normal')
    if self.pooling: self.pool = MaxPool2D(pool_size=(2,2))
    if self.rate is not None: self.drop = Dropout(rate)

  def call(self, inputs):
    x = self.conv1(inputs)
    if self.rate is not None: x = self.drop(x)
    x = self.conv2(x)
    if self.pooling:
      y = self.pool(x)
      return y, x
    else:
      return x

  def get_config(self):
    base_config = super().get_config()
    return {
        **base_config,
        "filters":self.filters,
        "rate":self.rate,
        "pooling":self.pooling
    }

# Expansion
class DecoderBlock(keras.layers.Layer):

  def __init__(self, filters, rate=None, axis=-1):
    super(DecoderBlock,self).__init__()
    self.filters = filters
    self.rate = rate
    self.axis = axis
    self.convT = Conv2DTranspose(self.filters,kernel_size=3,strides=2,padding='same')
    self.conv1 = Conv2D(self.filters, kernel_size=3, activation='relu', kernel_initializer='he_normal', padding='same')
    if rate is not None: self.drop = Dropout(self.rate)
    self.conv2 = Conv2D(self.filters, kernel_size=3, activation='relu', kernel_initializer='he_normal', padding='same')

  def call(self, inputs):
    X, short_X = inputs
    ct = self.convT(X)
    c_ = concatenate([ct, short_X], axis=self.axis)
    x = self.conv1(c_)
    if self.rate is not None: x = self.drop(x)
    y = self.conv2(x)
    return y

  def get_config(self):
    base_config = super().get_config()
    return {
        **base_config,
        "filters":self.filters,
        "rate":self.rate,
        "axis":self.axis,
    }

# Callback
class ShowProgress(keras.callbacks.Callback):
  def __init__(self, save=False):
    self.save = save
  def on_epoch_end(self, epoch, logs=None):
    id = np.random.randint(len(images))
    real_img = images[id][np.newaxis,...]
    pred_mask = self.model.predict(real_img).reshape(128,128)
    enhanced_mask = enhance_contrast(pred_mask)
    proc_mask1 = post_process(enhanced_mask)
    proc_mask2 = post_process(enhanced_mask, threshold=0.5)
    proc_mask3 = post_process(enhanced_mask, threshold=0.9)
    mask = masks[id].reshape(128,128)

    plt.figure(figsize=(10,5))

    plt.subplot(1,6,1)
    show_image(real_img[0], title="Orginal Image")

    plt.subplot(1,6,2)
    show_image(pred_mask, title="Predicted Mask", cmap='gray')

    plt.subplot(1,6,3)
    show_image(mask, title="Orginal Mask", cmap='gray')

    plt.subplot(1,6,4)
    show_image(proc_mask1, title="Processed@0.4", cmap='gray')

    plt.subplot(1,6,5)
    show_image(proc_mask2, title="Processed@0.5", cmap='gray')

    plt.subplot(1,6,6)
    show_image(proc_mask3, title="Processed@0.9", cmap='gray')

    plt.tight_layout()
    if self.save: plt.savefig("Progress-{}.png".format(epoch+1))
    plt.show()

inputs= Input(shape=(SIZE,SIZE,3))

# Contraction
p1, c1 = EncoderBlock(16,0.1)(inputs)
p2, c2 = EncoderBlock(32,0.1)(p1)
p3, c3 = EncoderBlock(64,0.2)(p2)
p4, c4 = EncoderBlock(128,0.2)(p3)

# Encoding Layer
c5 = EncoderBlock(256,rate=0.3,pooling=False)(p4)

# Expansion
d1 = DecoderBlock(128,0.2)([c5,c4]) # [current_input, skip_connection]
d2 = DecoderBlock(64,0.2)([d1,c3])
d3 = DecoderBlock(32,0.1)([d2,c2])
d4 = DecoderBlock(16,0.1, axis=3)([d3,c1])

# Outputs
outputs = Conv2D(1,1,activation='sigmoid')(d4)

unet = keras.models.Model(
    inputs=[inputs],
    outputs=[outputs],
)

unet.compile(
    loss='binary_crossentropy',
    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
    metrics=['accuracy']
)

callbacks = [
    EarlyStopping(patience=3, restore_best_weights=True),
    ModelCheckpoint('UNet-01.h5',save_best_only=True),
    ShowProgress(save=True)
]

unet.summary()

# Commented out IPython magic to ensure Python compatibility.
# %%time
# with tf.device("/GPU:0"):
#   results = unet.fit(
#       X, y,
#       epochs=100,
#       callbacks=callbacks,
#       validation_split=0.1,
#       batch_size=16
#   )

